#!/usr/bin/env python2.7
import argparse
import json
import csv
import sys

EXTRA_PATH = "/data/bff-results/bff/results/crashers/%s/%s"

"""
Something this code needs to do:
  The ground truth data will include potentially multiple seps per bug. What 
  we should do is keep a map from the sets of fixes to (potentailly) fresh
  integers, and "flatten" the data out into a first order map from one crasher
  to one identifier. Then our comparison algorithms will work normally. 

  We might have some different knobs to turn to make those flattening decisions 
  differently in the future. 
"""

def main(args):
  truths = {}
  truths["name"] = args.name
  truths["labels"] = []
  labels = {}
  fresh_label = 0
  reader = csv.reader(open(args.groundtruth, 'r'))
  for i in reader:
    status = i[1]
    path = i[3]
    vfixes = i[8]
    if status == "NORMAL":
      fixes = [ i.split(":")[0] for i in vfixes.split(" ")]
      fixes_s = frozenset(fixes)
      fixes_label = None
      if labels.has_key(fixes_s):
        fixes_label = labels[fixes_s]
      else:
        labels[fixes_s] = fresh_label
        fixes_label = fresh_label
        fresh_label = fresh_label + 1
      realpath = args.prefixdir + path.replace(EXTRA_PATH % (args.name, args.name), "")
      truths["labels"].append((realpath, fixes_label))

  output = open(args.outputfile, 'w')
  json.dump(truths, output)
  output.close()
  return 0

if __name__ == '__main__':
  parser = argparse.ArgumentParser("csvtool")
  parser.add_argument("name")
  parser.add_argument("groundtruth")
  parser.add_argument("outputfile")
  parser.add_argument("prefixdir")
  args = parser.parse_args()
  sys.exit(main(args))
